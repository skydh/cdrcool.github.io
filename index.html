<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Muse',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta property="og:type" content="website">
<meta property="og:title" content="OnePiece">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="OnePiece">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="晴天">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>OnePiece</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">OnePiece</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Do you know LosAngeles morning four-point looks like?</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/21/Elasticsearch%E8%AF%BB%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="晴天">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OnePiece">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/21/Elasticsearch%E8%AF%BB%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/" class="post-title-link" itemprop="url">Elasticsearch 读性能优化</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-21 12:29:00 / 修改时间：14:44:43" itemprop="dateCreated datePublished" datetime="2020-02-21T12:29:00+08:00">2020-02-21</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Elasticsearch/" itemprop="url" rel="index">
                    <span itemprop="name">Elasticsearch</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="数据建模"><a href="#数据建模" class="headerlink" title="数据建模"></a>数据建模</h2><ul>
<li>尽可能 Denormalize 数据，从而获取最佳性能<ul>
<li>使用 Nested 类型的数据，查询数据会慢几倍</li>
<li>使用 Parent/Child 关系，查询速度会慢几百倍</li>
</ul>
</li>
<li>尽量将数据先行计算，然后保存在 Elasticsearch 中，以避查询时的 Script 计算</li>
<li>尽量使用 Filter Context，利用缓存机制，同时减少不必要的算分</li>
<li>结合 profile、explain API 分析慢查询的问题，持续优化数据模型<ul>
<li>严禁使用 * 开头的通配符 Terms 查询</li>
</ul>
</li>
<li>聚合查询时，控制聚合的数量，以减少内存的开销</li>
</ul>
<h2 id="优化分片"><a href="#优化分片" class="headerlink" title="优化分片"></a>优化分片</h2><ul>
<li>避免 Over Sharing<br>一个查询需要访问每一个分片，分片过多，会导致不必要的查询开销</li>
<li>结合应用场景，控制单个分片的尺寸<br>Search: 200GB Logging: 400GB</li>
<li>Force-merge Read-only 索引<br>使用基于时间序列的索引，将只读的索引进行 force merge，减少 segment 数量</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/21/Elasticsearch%E5%86%99%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="晴天">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OnePiece">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/21/Elasticsearch%E5%86%99%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/" class="post-title-link" itemprop="url">Elasticsearch 写性能优化</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-21 11:25:00 / 修改时间：12:22:42" itemprop="dateCreated datePublished" datetime="2020-02-21T11:25:00+08:00">2020-02-21</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Elasticsearch/" itemprop="url" rel="index">
                    <span itemprop="name">Elasticsearch</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h2><ul>
<li>多线程写入</li>
<li>使用 Bulk API 进行批量写<ul>
<li>单个 Bulk 请求体的数据量不要太大，官方建议大约 5-15 mb</li>
<li>写入端的 bulk 请求超时需要足够长，建议 60s 以上</li>
<li>写入端尽量将数据轮询达到不同的节点上 </li>
</ul>
</li>
</ul>
<h2 id="服务器端"><a href="#服务器端" class="headerlink" title="服务器端"></a>服务器端</h2><ul>
<li><p>降低 IO 操作</p>
<ul>
<li>使用 ES 自动生成文档的 id</li>
<li>设置 ES 配置（如 refresh_interval）</li>
</ul>
</li>
<li><p>降低 CPU 和存储开销</p>
<ul>
<li>减少不必要的分词</li>
<li>避免不必要的 doc_values（禁用后不能用于排序、聚合以及脚本访问）</li>
<li>文档的字段尽量保证相同的顺序（提高文档的压缩率）</li>
</ul>
</li>
<li><p>尽可能做到写入和分片的均衡负载，实现水平扩展</p>
<ul>
<li>使用 Shard Filtering 来控制将分配到哪个节点</li>
<li>Write Load Balancer</li>
<li>配置 index.routing.allocation.total_share_per_node，限定每个索引在每个节点上可分配的主分片数</li>
</ul>
</li>
<li><p>调整 Bulk 线程池和队列</p>
<ul>
<li>应使用固定大小（CPU 核数 + 1）的线程池，避免过多的上下文切换</li>
<li>队列大小可以适当增加，不要过大，否则占用的内存会成为 GC 的负担</li>
</ul>
</li>
</ul>
<h2 id="文档建模（关闭无关的功能）"><a href="#文档建模（关闭无关的功能）" class="headerlink" title="文档建模（关闭无关的功能）"></a>文档建模（关闭无关的功能）</h2><ul>
<li>只需要聚合不需要搜索，index 设置成 false</li>
<li>不需要算分，norms 设置成 false</li>
<li>对于指标型数据，关闭 _source，以减少 IO 操作</li>
<li>对于 Text 类型字段，不采用默认的 mapping，应结合实际需求人工设定</li>
<li>不要对字符串使用默认的 dynamic mapping（字段数量过多，会对性能产生较大的影响）</li>
<li>合理设置 index_options: doc |freqs | positions | offsets。（Text 类型默认记录级别为 positions，其它类型默认为 docs。记录内容越多，占用的存储空间越大。）</li>
</ul>
<h2 id="性能取舍"><a href="#性能取舍" class="headerlink" title="性能取舍"></a>性能取舍</h2><p>如果需要追求极致的写入速度，可以牺牲数据可靠性及搜索实时性以换取性能。</p>
<ul>
<li>牺牲可靠性：将副本分片设置为 0，写入完毕再调整回去</li>
<li>牺牲搜索实时性：增加 refresh_interval 的时间，默认 1s；增大 indices.memory.index_bufer_size，默认是 10%，会导致自动触发 refresh</li>
<li>牺牲可靠性：修改 translog 的配置，默认每次请求都会异步落盘</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/20/Redis%E9%81%8D%E5%8E%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="晴天">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OnePiece">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/20/Redis%E9%81%8D%E5%8E%86/" class="post-title-link" itemprop="url">Redis 遍历</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-20 12:11:00 / 修改时间：12:59:58" itemprop="dateCreated datePublished" datetime="2020-02-20T12:11:00+08:00">2020-02-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>在平时线上 Redis 维护工作中，有时候需要从 Redis 实例成千上万的 key 中找出特定前缀的 key 列表来手动处理数据，可能是修改它的值，也可能是删除 key。这里就有一个问题，如果从海量的 key 中找出满足特定前缀的 key 列表来？</p>
<h2 id="keys"><a href="#keys" class="headerlink" title="keys"></a>keys</h2><p>Redis 提供了一个简单暴力的指令 keys 用来列出所有满足特定正则字符串规则的 key。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">keys *</span><br><span class="line"></span><br><span class="line">keys codehole*</span><br><span class="line"></span><br><span class="line">keys code*hole</span><br></pre></td></tr></table></figure>

<p>这个指令使用非常简单，提供一个简单的正则字符串即可，但是有很明显的缺点：keys 算法是遍历算法，复杂度是 O(n)，且该指令没有 offset、limit 参数，如果实例中有千万级以上的 key，这个指令就会导致 Redis 服务卡顿，所有读写 Redis 的其它指令都会被延后甚至超时报错，因为 Redis 是单线程程序，顺序执行所有指令，其它指令必须等到当前的 keys 指令执行完了才可以继续。</p>
<h2 id="scan"><a href="#scan" class="headerlink" title="scan"></a>scan</h2><p>Redis 为了解决这个问题，还提供了 scan 指令， scan 相比 keys 具备以下特点：</p>
<ol>
<li>复杂度虽然也是 O(n)，但是它是通过游标分布进行的，不会阻塞线程；</li>
<li>提供 limit 参数，可以控制每次返回结果的最大条数，limit 只是一个 hint，返回的结果可多可少；</li>
<li>同 keys 一样，它也提供模式匹配功能；</li>
<li>服务器不需要为游标保存状态，游标的唯一状态就是 scan 返回给客户端的游标整数；</li>
<li>返回的结果可能会有重复，需要客户端去重，这点非常重要；</li>
<li>遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的；</li>
<li>每次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零。</li>
</ol>
<h3 id="scan-基础使用"><a href="#scan-基础使用" class="headerlink" title="scan 基础使用"></a>scan 基础使用</h3><p>scan 参数提供了 3 个参数，第一个是 cursor 整数值，第二个是 key 的正则模式，第三个是遍历的 limit hint。第一次遍历时，cursor 值为 0，然后将返回结果中第一个整数值作为下一次遍历的 cursor。一直遍历到返回的 cursor 值为 0 时结束。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; scan 0 match key99* count 1000</span><br><span class="line">1) <span class="string">"13976"</span></span><br><span class="line">2)  1) <span class="string">"key9911"</span></span><br><span class="line">    2) <span class="string">"key9974"</span></span><br><span class="line">    3) <span class="string">"key9994"</span></span><br><span class="line">    4) <span class="string">"key9910"</span></span><br><span class="line">    5) <span class="string">"key9907"</span></span><br><span class="line">    6) <span class="string">"key9989"</span></span><br><span class="line">    7) <span class="string">"key9971"</span></span><br><span class="line">    8) <span class="string">"key99"</span></span><br><span class="line">    9) <span class="string">"key9966"</span></span><br><span class="line">   10) <span class="string">"key992"</span></span><br><span class="line">   11) <span class="string">"key9903"</span></span><br><span class="line">   12) <span class="string">"key9905"</span></span><br><span class="line">127.0.0.1:6379&gt; scan 13976 match key99* count 1000</span><br><span class="line">1) <span class="string">"1996"</span></span><br><span class="line">2)  1) <span class="string">"key9982"</span></span><br><span class="line">    2) <span class="string">"key9997"</span></span><br><span class="line">    3) <span class="string">"key9963"</span></span><br><span class="line">    4) <span class="string">"key996"</span></span><br><span class="line">    5) <span class="string">"key9912"</span></span><br><span class="line">    6) <span class="string">"key9999"</span></span><br><span class="line">    7) <span class="string">"key9921"</span></span><br><span class="line">    8) <span class="string">"key994"</span></span><br><span class="line">    9) <span class="string">"key9956"</span></span><br><span class="line">   10) <span class="string">"key9919"</span></span><br><span class="line">127.0.0.1:6379&gt; scan 1996 match key99* count 1000</span><br><span class="line">1) <span class="string">"12594"</span></span><br><span class="line">2) 1) <span class="string">"key9939"</span></span><br><span class="line">   2) <span class="string">"key9941"</span></span><br><span class="line">   3) <span class="string">"key9967"</span></span><br><span class="line">   4) <span class="string">"key9938"</span></span><br><span class="line">   5) <span class="string">"key9906"</span></span><br><span class="line">   6) <span class="string">"key999"</span></span><br><span class="line">   7) <span class="string">"key9909"</span></span><br><span class="line">   8) <span class="string">"key9933"</span></span><br><span class="line">   9) <span class="string">"key9992"</span></span><br><span class="line">......</span><br><span class="line">127.0.0.1:6379&gt; scan 11687 match key99* count 1000</span><br><span class="line">1) <span class="string">"0"</span></span><br><span class="line">2)  1) <span class="string">"key9969"</span></span><br><span class="line">    2) <span class="string">"key998"</span></span><br><span class="line">    3) <span class="string">"key9986"</span></span><br><span class="line">    4) <span class="string">"key9968"</span></span><br><span class="line">    5) <span class="string">"key9965"</span></span><br><span class="line">    6) <span class="string">"key9990"</span></span><br><span class="line">    7) <span class="string">"key9915"</span></span><br><span class="line">    8) <span class="string">"key9928"</span></span><br><span class="line">    9) <span class="string">"key9908"</span></span><br><span class="line">   10) <span class="string">"key9929"</span></span><br><span class="line">   11) <span class="string">"key9944"</span></span><br></pre></td></tr></table></figure>

<p>从上面的过程可以看到虽然提供的 limit 是 1000，但是返回的结果只有 10 个左右。因为这个 limit 不是限定返回结果的数量，而是限定服务器单次遍历的字典槽位数量(约等于)。如果将 limit 设置为 10，会发现返回结果是空的，但是游标值不为零，意味着遍历还没结束。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; scan 0 match key99* count 10</span><br><span class="line">1) <span class="string">"3072"</span></span><br><span class="line">2) (empty list or <span class="built_in">set</span>)</span><br></pre></td></tr></table></figure>

<h3 id="字典的结构"><a href="#字典的结构" class="headerlink" title="字典的结构"></a>字典的结构</h3><p>在 Redis 中所有的 key 都存储在一个很大的字典中，这个字典的结构和 Java 中的HashMap 一样，是一维数组 + 二维链表结构，第一维数组的大小总是 2^n(n&gt;=0)，扩容一次数组大小空间加倍，也就是 n++。</p>
<p><img src="/images/redis/Redis%E5%AD%97%E5%85%B8%E7%BB%93%E6%9E%84.jpg" alt="Redis字典结构"></p>
<p>scan 指令返回的游标就是第一维数组的位置索引，我们将这个位置索引称为槽 (slot)。如果不考虑字典的扩容缩容，直接按数组下标挨个遍历就行了。limit 参数就表示需要遍历的槽位数，之所以返回的结果可能多可能少，是因为不是所有的槽位上都会挂接链表，有些槽位可能是空的，还有些槽位上挂接的链表上的元素可能会有多个。每一次遍历都会将 limit 数量的槽位上挂接的所有链表元素进行模式匹配过滤后，一次性返回给客户端。</p>
<h3 id="scan-遍历顺序"><a href="#scan-遍历顺序" class="headerlink" title="scan 遍历顺序"></a>scan 遍历顺序</h3><p>scan 的遍历顺序非常特别。它不是从第一维数据的第 0 位一直遍历到末尾，而是采用了<strong>高位进位加法</strong>来遍历。之所以使用这样特殊的方式进行遍历，是考虑到<strong>字典的扩容和缩容时避免槽位的遍历重复和遗漏</strong>。</p>
<p>首先我们用动画演示以下普通的加法和高位进位加法的区别。</p>
<p><img src="/images/redis/%E9%AB%98%E4%BD%8D%E8%BF%9B%E4%BD%8D%E5%8A%A0%E6%B3%95%E6%BC%94%E7%A4%BA.gif" alt="高位进位加法演示"></p>
<h2 id="更多的-scan-指令"><a href="#更多的-scan-指令" class="headerlink" title="更多的 scan 指令"></a>更多的 scan 指令</h2><p>scan 指令是一系列指令，除了可以遍历所有的 key 之外，还可以对指定的容器集合进行遍历。比如 hscan 遍历 hash 字典的元素、sscan 遍历 set 集合的元素、zscan 遍历 zset 集合的元素。</p>
<p>它们的原理同 scan 都会类似的，因为 hash 底层就是字典，set 也是一个特殊的 hash，zset 内部也使用了字典来存储所有的元素内容，所以这里不再赘述。</p>
<h2 id="大-key-扫描"><a href="#大-key-扫描" class="headerlink" title="大 key 扫描"></a>大 key 扫描</h2><p>有时候会因为业务人员使用不当，在 Redis 实例中会形成很大的对象，比如一个很大的 hash，一个很大的 zset 这都是经常出现的。这样的对象对 Redis 的集群数据迁移带来了很大的问题，因为在集群环境下，如果某个 key 太大，会数据导致迁移卡顿。另外在内存分配上，如果一个 key 太大，那么当它需要扩容时，会一次性申请更大的一块内存，这也会导致卡顿。如果这个大 key 被删除，内存会一次性回收，卡顿现象会再一次产生。</p>
<p>如果我们观察到 Redis 的内存大起大落，这极有可能是因为大 key 导致的，这时候就需要定位出具体是那个 key，进一步定位出具体的业务来源，然后再改进相关业务代码设计。</p>
<p>为了避免对线上 Redis 带来卡顿，这就要用到 scan 指令，对于扫描出来的每一个 key，使用 type 指令获得 key 的类型，然后使用相应数据结构的 size 或者 len 方法来得到它的大小，对于每一种类型，保留大小的前 N 名作为扫描结果展示出来。</p>
<p>上面这样的过程需要编写脚本，比较繁琐，不过 Redis 官方已经在 redis-cli 指令中提供了这样的扫描功能，我们可以直接拿来即用。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 7001 –-bigkeys</span><br></pre></td></tr></table></figure>

<p>如果你担心这个指令会大幅抬升 Redis 的 ops 导致线上报警，还可以增加一个休眠参数。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 7001 –-bigkeys -i 0.1</span><br></pre></td></tr></table></figure>

<p>上面这个指令每隔 100 条 scan 指令就会休眠 0.1s，ops 就不会剧烈抬升，但是扫描的时间会变长。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/19/Redis%E5%AE%89%E5%85%A8%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="晴天">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OnePiece">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/19/Redis%E5%AE%89%E5%85%A8%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/" class="post-title-link" itemprop="url">Redis 安全注意事项</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-19 21:16:00 / 修改时间：21:49:29" itemprop="dateCreated datePublished" datetime="2020-02-19T21:16:00+08:00">2020-02-19</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="指令安全"><a href="#指令安全" class="headerlink" title="指令安全"></a>指令安全</h2><p>Redis 中有一些非常危险的指令，这些指令会对 Redis 的稳定以及数据安全造成非常严重的影响。比如 <strong>keys</strong> 指令会导致 Redis 卡顿，<strong>flushdb</strong> 和 <strong>flushall</strong> 会让 Redis 中的所有数据全部清空。</p>
<p>Redis 在配置文件中提供了 <strong>rename-command</strong> 指令用于将某些危险的指令改成特别的名称，用来避免人为误操作。比如在配置文件的 security 块增加以下内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rename-command keys abckeyabc</span><br></pre></td></tr></table></figure>

<p>如果还想执行 keys 指令，那就不能再敲 keys 指令了，而需要键入 abckeyabc。如果想完全封杀某条命令，可以将指令 rename 成空串，就无法通过任何字符串指令来执行这条指令了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rename-command flushall &quot;&quot;</span><br></pre></td></tr></table></figure>

<h2 id="端口安全"><a href="#端口安全" class="headerlink" title="端口安全"></a>端口安全</h2><p>Redis 默认会监听 6379 端口，如果当前的服务器主机有外网地址，Redis 的服务将会直接暴露再公网上，任何一个初级黑客使用适当的工具对 IP 地址进行端口扫描就可以探测出来。</p>
<p>所以，运维人员必须在 Redis 的配置文件中指定监听的 IP 地址，从而避免这样的惨剧发生。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bind 10.100.20.13</span><br></pre></td></tr></table></figure>

<p>更进一步，还可以增加 Redis 的密码访问限制，客户端必须使用 auth 指令传入正确的密码才可以访问 Redis，这样即使地址暴露出去了，普通黑客也无法对 Redis 进行任何指令操作。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requirepass yoursecurepasswordhereplease</span><br></pre></td></tr></table></figure>

<p>密码控制也会影响到从库复制，从库必须在配置文件里使用 masterauth 指令配置相应的密码才可以进行复制操作。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">masterauth yoursecurepasswordhereplease</span><br></pre></td></tr></table></figure>

<h2 id="Lua-脚本安全"><a href="#Lua-脚本安全" class="headerlink" title="Lua 脚本安全"></a>Lua 脚本安全</h2><p>开发者必须禁止 Lua 脚本由用户输入的内容（UGC）生成，这可能会被黑客利用以植入恶意的攻击代码来得到 Redis 的主机权限。</p>
<p>同时，我们应该让 Redis 以普通用户的身份启动，这样即使存在恶意代码黑客也无法拿到 root 权限。</p>
<h2 id="SSL-代理"><a href="#SSL-代理" class="headerlink" title="SSL 代理"></a>SSL 代理</h2><p>Redis 并不支持 SSL 链接，意味着客户端和服务器之间交互的数据不应该直接暴露在公司网上传输，否则会有被窃听的风险。如果必须要用在公网上，可以考虑使用 SSL 代理。</p>
<p>SSL 代理比较常见的有 ssh，不过 Redis 官方推荐使用 spiped 工具，可能是因为 spiped 的功能相对比较单一，使用也比较简单，易于理解。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/19/Redis%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="晴天">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OnePiece">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/19/Redis%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/" class="post-title-link" itemprop="url">Redis 布隆过滤器</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-19 20:05:00 / 修改时间：21:07:45" itemprop="dateCreated datePublished" datetime="2020-02-19T20:05:00+08:00">2020-02-19</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>布隆过滤器（Bloom Filter）是一种空间效率极高的概率型算法和数据结构，主要用来判断一个元数是否在集合中存在。<br>因为它是一个概率型的算法，所以会存在一定的误差，如果传入一个值去布隆过滤器中检索，可能会出现检测存在的结果实际上是不存在的，但是肯定不会出现实际上不存在却反馈存在的结果。<br>因此，布隆过滤器不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，布隆过滤器通过极少的错误换取了存储空间的极大节省。</p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>我们需要通过加载 module 来使用 Redis 中的布隆过滤器。使用 Docker 可以直接在 Redis 中体验布隆过滤器。 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 6379:6379 --name bloomfilter redislabs/rebloom</span><br><span class="line">docker <span class="built_in">exec</span> -it bloomfilter redis-cli</span><br></pre></td></tr></table></figure>

<p>Redis 布隆过滤器主要就 2 个指令:</p>
<ul>
<li>bf.add 添加元素到布隆过滤器中：<code>bf.add urls https://cdrcool.github.io</code>。</li>
<li>bf.exists 判断某个元素是否在过滤器中：<code>bf.exists urls https://cdrcool.github.io</code>。</li>
</ul>
<p>如果我们需要一次添加或查询多个元素，还可以使用以下 2 个指令：</p>
<ul>
<li>bf.madd 判断某个元素是否在过滤器中：<code>bf.exists urls https://cdrcool.github.io https://github.com</code>。</li>
<li>bf.mexists 判断某个元素是否在过滤器中：<code>bf.exists urls https://cdrcool.github.io https://github.com</code>。</li>
</ul>
<p>当我们调用 bd.add 或 bf.madd 指令时，如果此时布隆过滤器不存在，那么 Redis 会帮我们自动创建。Redis 其实还提供了自定义参数的布隆过滤器，需要我们在 add 之前使用 bf.reserve 指令显示创建，如：<code>bf.reserve urls 0.01 100</code>。<br>bf.reservee 有 3 个参数：</p>
<ul>
<li>key 过滤器的名字。</li>
<li>error_rate 允许布隆过滤器的错误率，这个值越低过滤器的位数组的大小越大，占用空间也就越大。</li>
<li>initial_size 布隆过滤器可以储存的元素个数，当实际存储的元素个数超过这个值之后，过滤器的准确率会下降。</li>
</ul>
<p>需要注意的是，在执行 bf.reservee 这个命令之前过滤器的名字应该不存在，不然会报错。</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>每个布隆过滤器对应到 Redis 的数据结构里面就是一个大型的 BitMap 和几个不一样的无偏 hash 函数。所谓无偏就是能够把元素的 hash 值算的比较均匀</p>
<p>向布隆过滤器中添加 key 时，会使用多个 hash 函数对 key 进行 hash 算的一个整数索引值然后对位数组长度进行取模运算得到一个位置，每个 hash 函数都会算的一个不同的位置，再把位数组的这几个位置都置为 1 就完成了 add 操作。</p>
<p>向布隆过滤器询问 key 是否存在时，跟 add 一样，也会把 hash 的几个位置都算出来，看看位数组中这几个位置是否都为 1，只要有一个位为 0，那么说明布隆过滤器中这个 key 不存在。如果都是 1，这并不能说明这个 key 就一定存在，只是极有可能存在，因为这些位置被置为 1 可能是因为其它的 key 存在所致。如果这个数组比较稀疏，判断正确的概率就会很大。</p>
<p>使用时不要让实际元素远大于初始化大小，当实际元素开始超出初始化大小时，应该对布隆过滤器进行重建，重新分配一个 size 更大的过滤器，再将所有的历史元素批量 add 进去(这就要求我们在其它的存储器中记录所有的历史元素)。</p>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><ul>
<li>爬虫系统中 URL 去重</li>
<li>邮箱系统中垃圾邮件过滤</li>
<li>推荐系统中新闻推荐 </li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://segmentfault.com/a/1190000016721700" target="_blank" rel="noopener">Redis 中的布隆过滤器</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/19/Redis%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F&%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF&%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="晴天">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OnePiece">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/19/Redis%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F&%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF&%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9/" class="post-title-link" itemprop="url">Redis 缓存穿透 & 缓存击穿 & 缓存雪崩</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-19 16:48:00 / 修改时间：19:54:16" itemprop="dateCreated datePublished" datetime="2020-02-19T16:48:00+08:00">2020-02-19</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><h3 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h3><p>缓存穿透是指缓存和数据库中都没有数据，而用户却不断在发起请求，如查找 id 为 -1 或特别大等不存在的的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ol>
<li>接口层增加校验，如用户鉴权校验，id 做基础校验，id &lt;= 的直接拦截。</li>
<li>对于缓存和数据库中都取不到的数据，可以将对应 key 的 value 设置为 null，同时设置 key 的过期时间，过期时间可以设置断点，如 30 秒，设置过长会导致正常情况下也查找不到数据。</li>
<li>使用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力。</li>
</ol>
<h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><h3 id="描述-1"><a href="#描述-1" class="headerlink" title="描述"></a>描述</h3><p>缓存击穿是指缓存中没有但数据库中有数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没有读到数据，又同时去数据库中查找数据，引起数据库压力瞬间增大，造成过大压力。</p>
<h3 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h3><ol>
<li>设置热点数据永不过期。</li>
<li>增加互斥锁，参考代码如下：</li>
</ol>
<p><img src="/images/redis/%E4%BA%92%E6%96%A5%E9%94%81%E7%A4%BA%E4%BE%8B.png" alt="互斥锁示例"></p>
<p>说明：</p>
<p>1) 缓存中有数据，直接走上述代码 13 行后就返回结果了；<br>2) 缓存中没有数据，第 1 个进入的线程，获取锁并从数据库去取数据，没释放锁之前，其他并行进入的线程会等待 100ms，再重新去缓存取数据。这样就防止都去数据库重复取数据，重复往缓存中更新数据情况出现。<br>3) 当然这是简化处理，理论上如果能根据 key 值加锁就更好了，就是线程 A 从数据库取 key1 的数据并不妨碍线程 B 取 key2 的数据，上面代码明显做不到这点。</p>
<h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><h3 id="描述-2"><a href="#描述-2" class="headerlink" title="描述"></a>描述</h3><p>缓存雪崩是值缓存中数据大批量到了过期时间，而查询数据量巨大，引起数据库压力过大甚至宕机。与缓存击穿不同的是缓存击穿是并发查找同一条数据，缓存雪崩是并发查找大量数据。</p>
<h3 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h3><ol>
<li>设置热点数据永远不过期。</li>
<li>缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。</li>
<li>如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。</li>
<li>缓存标记：记录缓存数据是否过期，如果过期会触发通知另外的线程在后台去更新实际 key 的缓存。</li>
</ol>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://blog.csdn.net/kongtiao5/article/details/82771694" target="_blank" rel="noopener">缓存穿透、缓存击穿、缓存雪崩区别和解决方案</a></li>
<li><a href="https://www.cnblogs.com/xichji/p/11286443.html" target="_blank" rel="noopener">REDIS缓存穿透，缓存击穿，缓存雪崩原因+解决方案</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/19/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="晴天">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OnePiece">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/19/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/" class="post-title-link" itemprop="url">Redis 分布式锁实现</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-19 12:30:00 / 修改时间：14:27:15" itemprop="dateCreated datePublished" datetime="2020-02-19T12:30:00+08:00">2020-02-19</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>分布式锁本质上要实现的目标就是在 Redis 里面占一个“茅坑”，当别的进程也要来占时，发现已经有人蹲在那里了，就只好放弃或者稍候再试。</p>
<p>占坑一般是使用 setnx(set if not exist) 指令，只允许被一个客户端占用。先来先占，再调用 del 指令释放茅坑。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">setnx lock:codehole <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">... <span class="keyword">do</span> something critical ...</span><br><span class="line"></span><br><span class="line">del lock:codehole</span><br></pre></td></tr></table></figure>

<p>但是有个问题，如果逻辑执行到中间出现异常了，可能会导致 del 指令没有被调用，这样就会陷入死锁，锁永远得不到释放。</p>
<p>于是我们在拿到锁之后，再给锁加上一个过期时间，比如 5s，这样及时中间出现异常也可以保证 5s 之后锁会自动释放。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">setnx lock:codehole <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">expire lock:codehole 5</span><br><span class="line"></span><br><span class="line">... <span class="keyword">do</span> something critical ...</span><br><span class="line"></span><br><span class="line">del lock:codehole</span><br></pre></td></tr></table></figure>

<p>但是以上逻辑还有问题。如果再 setnx 和 expire 之间服务进程突然挂掉了，可能是因为机器掉电或者被人为杀掉的，就会导致 expire 得不到执行，也会造成死锁。</p>
<p>这种问题的根源就在于 setnx 和 expire 是两条指令而不是原子指令，所以我们应该使用这两个指定的原子指令。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> lock:codehole <span class="literal">true</span> ex 5 nx</span><br><span class="line"></span><br><span class="line">... <span class="keyword">do</span> something critical ...</span><br><span class="line"></span><br><span class="line">del lock:codehole</span><br></pre></td></tr></table></figure>

<h2 id="超时问题"><a href="#超时问题" class="headerlink" title="超时问题"></a>超时问题</h2><p>Redis 分布式锁不能解决超时问题，如果在加锁和释放锁之间的逻辑执行时间太长，以至于超出了锁的超时限制，就会出现问题。因为这时候第一个线程持有的锁过期了，临界区的逻辑还没有执行完，这个时候第二个线程就提前重新持有了这把锁，导致临界区代码不能得到严格的串行化执行。</p>
<p>为了避免这个问题，Redis 分布式锁不要用于较长时间的任务。如果真的偶尔出现了，数据出现的小波错乱可能需要人工介入结解决。</p>
<p>有一个稍微安全一点的方案是为 set 指令的 value 参数设置为一个随机数，释放锁时先匹配随机数是否一致，然后再删除 key，这是为了确保当前线程占有的锁不会被其它线程释放，除非这个锁时过期了被服务器自动释放的。但是匹配 value 和删除 key 不是一个原子操作，Redis 也没有提供类似于 delifequals 这样的指令，这就需要使用 Lua 脚本来处理了，因为 Lua 脚本可以保证连续多个指令的原子性执行。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># delifequals</span></span><br><span class="line"><span class="keyword">if</span> redis.call(<span class="string">"get"</span>, KEYS[1]) == ARGV[1] <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">return</span> redis.call(<span class="string">"del"</span>, KEYS[1])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">return</span> 0</span><br><span class="line">end</span><br></pre></td></tr></table></figure>

<p>但是这也不是一个完美的方案，它只是相对安全一点，因为如果真的超时了，当前线程的逻辑没有执行完，其它线程也会乘虚而入。</p>
<h2 id="可重入性"><a href="#可重入性" class="headerlink" title="可重入性"></a>可重入性</h2><p>可重入性是指线程在持有锁的情况下再次请求加锁，如果一个锁支持同一个线程的多次加锁，那么这个锁就是可重入的。Redis 分布式锁如果要支持可重入，需要对客户端的 set 方法进行包装，使用线程的 Threadlocal 变量存储当前持有锁的计数。</p>
<p>不推荐使用可重入锁，它加重了客户端的复杂性，在编写业务方法时注意在逻辑结构上进行调整完全可以不适用可重入锁。</p>
<h2 id="Readlock"><a href="#Readlock" class="headerlink" title="Readlock"></a>Readlock</h2><p>在集群环境下，前面的分布式锁实现是有缺陷的，它不是绝对安全的，</p>
<p>比如在 Sentinel 集群中，主节点挂掉时，从节点会取而代之，客户端上却并没有明显感知。原先第一个客户端在主节点中申请成功了一把锁，但是这把锁还没有来得及同步到从节点，主节点突然挂掉了。然后从节点变成了主节点，这个新的节点内部没有这个锁，所以当一个客户端过来请求加锁时，立即就批准了。这样就会导致系统中同样一把锁被两个客户端同时持有，不安全性由此产生。</p>
<p>不过这种不安全也仅仅是在主从发生 failover 的情况下才会产生，而且持续时间极短，业务系统多数情况下可以容忍。</p>
<p>为了解决这个问题，Redis 提供了 Readlock。要使用 Readlock，需要提供多个 Redis 实例，这些实例之前相互独立没有主从关系。同很多分布式算法一样，Readloack 也使用“大多数机制”。</p>
<p>使用 Readlock 也是有代价的，需要更多的 Redis 实例，性能也下降了，代码上还需要引入额外的 library，运维上也需要特殊对待，这些都是需要考虑的成本。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/19/Redis%E7%BA%BF%E7%A8%8BIO%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="晴天">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OnePiece">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/19/Redis%E7%BA%BF%E7%A8%8BIO%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">Redis 线程 IO 模型</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-19 12:02:00 / 修改时间：12:29:03" itemprop="dateCreated datePublished" datetime="2020-02-19T12:02:00+08:00">2020-02-19</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Redis 采用的是<strong>基于内存的、单线程模型</strong>的 KV 数据库。官方提供的数据是可以达到 10w+ 的 QPS。这个数据不比采用单进程多线程的同样基于内存的 KV 数据库 Memcached 差。</p>
<h2 id="理解单线程模型"><a href="#理解单线程模型" class="headerlink" title="理解单线程模型"></a>理解单线程模型</h2><p><img src="/images/redis/%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.png" alt="单线程模型实例"></p>
<ol>
<li>Redis 会将每个客户端都关联一个指令队列。客户端的指令通过队列来按顺序处理，先到先服务。</li>
<li>在一个客户端的指令队列中的指令是顺序执行的，但是多个指令队列中的指令是无法保证顺序的，例如执行完 client-0 的队列中的 command-0 后，接下去是执行哪个队列中的第一个指令是无法确定的，但是肯定不会同时执行两个指令。</li>
<li>Redis 同样也会为每个客户端关联一个响应队列，通过响应队列来顺序地将指令的返回结果回复给客户端。</li>
<li>同样，一个响应队列中的消息可以顺序的回复给客户端，多个响应队列之间是无法保证顺序的。</li>
<li>所有的客户端的队列中的指令或者响应，Redis 每次都只能处理一个，同一时间绝对不会处理超过一个指令或者响应。</li>
</ol>
<h2 id="为什么-Redis-使用单线程模型还能保证高性能"><a href="#为什么-Redis-使用单线程模型还能保证高性能" class="headerlink" title="为什么 Redis 使用单线程模型还能保证高性能"></a>为什么 Redis 使用单线程模型还能保证高性能</h2><ul>
<li><p>纯内存访问<br>Redis 将所有数据放在内存中，内存的响应时长大约为 100 纳秒，这是 Redis 的 QPS 过万的重要基础。</p>
</li>
<li><p>非阻塞式 IO</p>
<ul>
<li><p>什么是阻塞式 IO<br>当我们调用 Scoket 的读写方法，默认它们是阻塞的。<br>read() 方法要传递进去一个参数 n，表示读取这么多字节后再返回，如果没有读够 n 字节线程就会阻塞，直到新的数据到来或者连接关闭了， read 方法才可以返回，线程才能继续处理。<br>write() 方法会首先把数据写到系统内核为 Scoket 分配的写缓冲区中，当写缓存区满溢，即写缓存区中的数据还没有写入到磁盘，就有新的数据要写道写缓存区时，write() 方法就会阻塞，直到写缓存区中有空闲空间。</p>
</li>
<li><p>什么是非阻塞式 IO<br>非阻塞 IO 在 Scoket 对象上提供了一个选项 Non_Blocking ，当这个选项打开时，读写方法不会阻塞，而是能读多少读多少，能写多少写多少。<br>能读多少取决于内核为 Scoket 分配的读缓冲区的大小，能写多少取决于内核为 Scoket 分配的写缓冲区的剩余空间大小。读方法和写方法都会通过返回值来告知程序实际读写了多少字节数据。</p>
</li>
</ul>
</li>
</ul>
<p>有了非阻塞 IO 意味着线程在读写 IO 时可以不必再阻塞了，读写可以瞬间完成然后线程可以继续干别的事了。</p>
<ul>
<li><p>IO 多路复用<br>“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗）。可以直接理解为：单线程的原子操作，避免上下文切换的时间和性能消耗；加上对内存中数据的处理速度，很自然的提高 Redis 的吞吐量</p>
</li>
<li><p>数据结构简单<br>单线程可以简化数据结构和算法的实现。并发数据结构实现不但困难而且开发测试比较麻。<br>Redis 全程使用 hash 结构，读取速度快，还有一些特殊的数据结构，对数据存储进行了优化，如压缩表对短数据进行压缩存储，再如跳表使用有序的数据结构加快读取的速度。</p>
</li>
<li><p>单线程避免了线程切换和竞态产生的消耗<br>单线程避免了线程切换和竞态产生的消耗，对于服务端开发来说，锁和线程切换通常是性能杀手。</p>
</li>
</ul>
<h2 id="单线程的问题"><a href="#单线程的问题" class="headerlink" title="单线程的问题"></a>单线程的问题</h2><ul>
<li>对于每个命令的执行时间是有要求的。如果某个命令执行过长，会造成其他命令的阻塞，所以 redis 适用于那些需要快速执行的场景。</li>
<li>无法发挥多核CPU性能，不过可以通过在单机开多个 Redis 实例来完善。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/18/Redis%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E5%8F%8A%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="晴天">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OnePiece">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/18/Redis%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E5%8F%8A%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/" class="post-title-link" itemprop="url">Redis 过期策略及内存淘汰策略</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-18 14:04:00" itemprop="dateCreated datePublished" datetime="2020-02-18T14:04:00+08:00">2020-02-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-19 11:54:07" itemprop="dateModified" datetime="2020-02-19T11:54:07+08:00">2020-02-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="过期策略"><a href="#过期策略" class="headerlink" title="过期策略"></a>过期策略</h2><p>Redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定时遍历这个字典来删除到期的 key。除了定时遍历之外，它还会使用惰性策略来删除过期的 key。所谓惰性删除就是在客户端访问这个 key 的时候，Redis 对 key 的过期时间进行检查，如果过期了就立即删除。<strong>定时删除是集中处理，惰性删除时零散处理。</strong></p>
<h3 id="定时扫描策略"><a href="#定时扫描策略" class="headerlink" title="定时扫描策略"></a>定时扫描策略</h3><p>Redis 默认会每秒进行 10 次过期扫描，过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。</p>
<ol>
<li>从过期字典中随机 20 个 key；</li>
<li>删除这 20 个 key 中已经过期的 key；</li>
<li>如果过期的 key 比率超过了 1/4，那就重复步骤 1；</li>
</ol>
<p>同时，为了保证过期扫描不会出现循环过度，导致线程卡死现象，算法还增加了扫描时间的上限，默认不会超过 25ms。</p>
<p>如果一个大型的 Redis 实例中所有的 key 在同一时间过期，Redis 会持续扫描过期字典（循环多次），直到过期字典中过期的 key 变得稀疏，或等待时间超过 25ms，这就会导致线上读写请求出现明显的卡顿现象，甚至大量的链接因为超时而关闭，业务端就会出现很多异常。而且这是我们还无法从 Redis 的 showlog 中看到慢查询记录，因为慢查询指的时逻辑处理过程慢，不包含等待时间。</p>
<p>所以<strong>业务开发人员一定要注意过期时间，如果有大批量的 key 过期，要给过期时间设置一个随机范围，从而分散过期处理的压力</strong>。</p>
<h3 id="从库的过期策略"><a href="#从库的过期策略" class="headerlink" title="从库的过期策略"></a>从库的过期策略</h3><p>从库不会进行过期扫描，从库对过期的处理是被动的。主库在 key 到期时，会在 AOF 文件里面增加一条 del 指令，然后同步到所有的从库，从库通过执行这条 del指令来删除过期的 key。</p>
<p>因为指令同步时异步进行的，所以主库过期的 key 的 del 指令没有及时同步到从库的话，会出现主从数据的不一致。</p>
<h2 id="内存淘汰策略"><a href="#内存淘汰策略" class="headerlink" title="内存淘汰策略"></a>内存淘汰策略</h2><p>当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换（swap）。交换会让 Redis 的性能急剧下降，对于访问量比较频繁的 Redis 来说，这样龟速的存取效率基本上等于不可用。</p>
<p>在生产环境中我们是不允许 Redis 出现交换行为，为了限制最大使用内存，Redis 提供了配置参数 maxmemory 来限制内存超出期望大小。</p>
<p>当实际内存超出 maxmemory 时，Redis 提供了几种可选策略（maxmemory-policy）来让用户自己觉醒该如何腾出新的空间以继续提供读写服务。</p>
<h3 id="noeviction"><a href="#noeviction" class="headerlink" title="noeviction"></a>noeviction</h3><p>不会继续服务器写请求（DEL 请求可以继续服务），读请求可以继续进行。这样可以保证不会丢失数据，但是会让线上的业务不能持续进行。这是默认的淘汰策略。</p>
<h3 id="volatile-lru"><a href="#volatile-lru" class="headerlink" title="volatile-lru"></a>volatile-lru</h3><p>尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。</p>
<h3 id="volatile-ttl"><a href="#volatile-ttl" class="headerlink" title="volatile-ttl"></a>volatile-ttl</h3><p>跟上面一样，除了淘汰的策略不是 LRU，而是 key 的剩余寿命 ttl 的值，ttl 越小越优先被淘汰。</p>
<h3 id="volatile-random"><a href="#volatile-random" class="headerlink" title="volatile-random"></a>volatile-random</h3><p>跟上面一样，不过淘汰的 key 是过期 key 集合中随机的 key。</p>
<h3 id="allkeys-lru"><a href="#allkeys-lru" class="headerlink" title="allkeys-lru"></a>allkeys-lru</h3><p>区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰。</p>
<h3 id="allkeys-random"><a href="#allkeys-random" class="headerlink" title="allkeys-random"></a>allkeys-random</h3><p>跟上面一样，不过淘汰的策略是随机的 key。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>volatile-xxx 策略只会针对带过期时间的 key 进行淘汰，allkeys-xxx 策略会对所有的 key 进行淘汰。如果我们只是拿 Redis 做缓存，那应该使用 allkeys-xxx，客户端写缓存时不必携带过期时间；如果我们还想同时使用 Redis 的持久化功能，那就使用 volatile-xxx 策略，这样可以保留没有设置过期时间的 key，它们是永久的 key 不会被 LRU 算法淘汰。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/18/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="晴天">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OnePiece">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/18/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/" class="post-title-link" itemprop="url">Redis 持久化机制</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-18 10:18:00 / 修改时间：19:41:43" itemprop="dateCreated datePublished" datetime="2020-02-18T10:18:00+08:00">2020-02-18</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Redis 的数据默认全部在内存里，如果突然宕机，数据就会全部丢失，因此必须有一种机制来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的持久化机制。</p>
<p>Redis 的持久化机制有两种：</p>
<ul>
<li>RDB 快照</li>
<li>AOF 日志</li>
</ul>
<p>RDB 快照是一次全量备份，AOF 日志是连续的增量备份；快照是内存数据的二进制序列化形式，在存储上非常紧凑，而 AOF 日志记录的是内存数据修改的指令记录文本。</p>
<h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><h3 id="RDB-快照"><a href="#RDB-快照" class="headerlink" title="RDB 快照"></a>RDB 快照</h3><p>优点：</p>
<ul>
<li>RDB 快照是紧凑的二进制文件，比较适合做冷备，全量复制的场景。</li>
<li>相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 Redis 进程，更加快速。</li>
</ul>
<p>缺点：</p>
<ul>
<li>如果想要在 Redis 实例发生故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。</li>
<li>RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。</li>
<li>RDB 无法实现实时或者秒级持久化。</li>
</ul>
<h3 id="AOF-日志"><a href="#AOF-日志" class="headerlink" title="AOF 日志"></a>AOF 日志</h3><p>优点：</p>
<ul>
<li>AOF 日志可以更好的保护数据不丢失。</li>
<li>AOF 日志文件以 append-only 模式写入，写入性能比较高。</li>
<li>AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。</li>
<li>适合做灾难性的误删除紧急恢复。</li>
</ul>
<p>缺点：</p>
<ul>
<li>对于同一份数据来说，AOF 日志文件通常比 RDB 快照文件更大，恢复速度慢。</li>
<li>AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 fsync 一次日志文件。（当然，每秒一次 fsync，性能也还是很高的。）</li>
<li>以前 AOF 发生过bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。</li>
</ul>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="RDB-快照-1"><a href="#RDB-快照-1" class="headerlink" title="RDB 快照"></a>RDB 快照</h3><p>默认情况下，Redis 是 RDB 快照的持久化方式，将内存中的数据以快照的方式写入二进制文件中，默认的文件名是 dump.rdb。</p>
<p>redis.conf 默认配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure>

<p>配置含义：</p>
<ul>
<li>900 秒内，如果超过 1 个 key 被修改，则发起快照保存。</li>
<li>300 秒内，如果超过 10 个 key 被修改，则发起快照保存。</li>
<li>60 秒内，如果 1 万个 key 被修改，则发起快照保存。</li>
</ul>
<h3 id="AOF-日志-1"><a href="#AOF-日志-1" class="headerlink" title="AOF 日志"></a>AOF 日志</h3><p>如果要开启 AOF 日志持久化方式，需要将 appendonly 设置为 yes。（开启后在服务端会发现多了一个 appendonly.aof 文件。）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">appendonly yes</span><br><span class="line"></span><br><span class="line"># 默认每秒持久化一次</span><br><span class="line"># appendfsync everysec</span><br></pre></td></tr></table></figure>

<p>默认是每秒持久化一次。通过指定不同的 appendfsync  值，可以实现不同的持久化策略。</p>
<ul>
<li>no：不主动进行同步操作，默认 30s 一次</li>
<li>everysec：每秒持久化一次(默认配置)</li>
<li>always：每次操作都会立即写入 aof 文件中</li>
</ul>
<h3 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aof-use-rdb-preamble yes</span><br></pre></td></tr></table></figure>

<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><h3 id="RDB-快照-2"><a href="#RDB-快照-2" class="headerlink" title="RDB 快照"></a>RDB 快照</h3><p>Redis 使用操作系统的多进程 COW（Copy On Write）机制来实现快照持久化。</p>
<p>Redis 在持久化时会调用 glibc 的函数 <strong>fork 产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求</strong>。</p>
<p>子进程刚刚产生时，它和父进程共享内存里面的代码段和数据段。我们可以将父子进程想象成一个连体婴儿，共享身体。这是 Linux 操作系统的机制，为了节约内存资源，所以尽可能让它们共享起来。在进程分离的一瞬间，内存的增长几乎没有明显变化。</p>
<p>子进程做数据持久化，它不会修改现有的的内容数据结构，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是父进程不一样，它必须持续服务客户端请求，然后对内存数据结构进行不间断的修改。</p>
<p>这个时候就会使用操作系统的 COW 机制来进行数据段页面的分离。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。</p>
<p>随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增长。但是也不会超过原有数据内存的 2 倍大小。另外一个 Redis 实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分页面。每个页面的大小只有 4k，一个 Redis 实例里一般都会由成千上万的页面。</p>
<p>子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么 Redis 的持久化叫做“快照”的原因。</p>
<h3 id="AOF-日志-2"><a href="#AOF-日志-2" class="headerlink" title="AOF 日志"></a>AOF 日志</h3><p>AOF 日志存储的是 Redis 服务器的顺序指令序列，AOF 日志只记录对内存进行修改的指令记录。</p>
<p>假设 AOF 日志记录了自 Redis 实例创建以来所有的修改性指令序列，那么就可以通过对一个空的 Redis 实例顺序执行所有的指令，也就是“重放”，来恢复 Redis 当前实例的内存数据结构的状态。</p>
<p>Redis 会在收到客户端修改指令后，进行参数校验进行逻辑处理后，如果没问题，就立即将该指令文本存储到 AOF 日志中，也就是<strong>先执行指令才将日志存盘</strong>。</p>
<p>Redis 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个 AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 AOF 日志瘦身。</p>
<h4 id="AOF-重写"><a href="#AOF-重写" class="headerlink" title="AOF 重写"></a>AOF 重写</h4><p>Redis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。</p>
<h4 id="fsync"><a href="#fsync" class="headerlink" title="fsync"></a>fsync</h4><p>AOF 日志是以文件的形式存在的，当程序对 AOF 日志文件进行写操作时，实际上是将内容写到了内核为文件描述符分配的一个内存缓存中，然后内核会异步将脏数据刷回到磁盘的。</p>
<p>这就意味着如果机器突然宕机，AOF 日志内容可能还没有来得及完全刷到磁盘中，这个时候就会出现日志丢失。那该怎么办？</p>
<p>Linux 的 glibc 提供了 fsync(int fd) 函数可以将指定文件的内容强制从内核缓存刷到磁盘。只要 Redis 进程实时调用 fsync 函数就可以保证 aof 日志不丢失。但是 fsync 是一个磁盘 IO 操作，它很慢！如果 Redis 执行一条指令就要 fsync 一次，那么 Redis 高性能的地位就不保了。</p>
<p>所以在生产环境的服务器中，Redis 通常是每隔 1s 左右执行一次 fsync 操作，周期 1s 是可以配置的。这是在数据安全性和性能之间做了一个折中，在保持高性能的同时，尽可能使得数据少丢失。</p>
<p>Redis 同样也提供了另外两种策略，一个是从不 fsync–让操作系统来决定何时同步磁盘，很不安全，另一个是来一个指令就 fsync 一次–非常慢。这两种策略在生产环境基本不会使用。</p>
<h2 id="混合持久化-1"><a href="#混合持久化-1" class="headerlink" title="混合持久化"></a>混合持久化</h2><p>重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。</p>
<p>Redis 4.0 为了解决这个问题，带来了一个新的持久化选项：混合持久化。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。</p>
<p>于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。</p>
<p>当然混合持久化也是有缺点的，就是 aof 日志里面的 rdb 部分就是压缩格式不再是 aof 格式，可读性差。</p>
<h2 id="运维"><a href="#运维" class="headerlink" title="运维"></a>运维</h2><p>通常 Redis 的主节点不会进行持久化操作，持久化操作主要在从节点进行。从节点是备份节点，没有来自客户端请求的压力，它的操作系统资源往往比较充沛。</p>
<p>但是如果出现网络分区，从节点长期连不上主节点，就会出现数据不一致的问题，特别是在网络分区初出现的情况下又不小心主节点宕机了，那么数据就会丢失，所以在生产环境要做好实时监控工作，保证网络畅通或者能快速修复。另外还应该再增加一个从节点以降低网络分无的概率，只要有一个从节点数据同步正常，数据也就不会轻易丢失。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">晴天</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">61</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">晴天</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.7.0
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  


</body>
</html>
